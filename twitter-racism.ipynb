{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10651736,"sourceType":"datasetVersion","datasetId":6595809},{"sourceId":10651892,"sourceType":"datasetVersion","datasetId":6595919}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets emoji scikit-learn torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:30:14.940534Z","iopub.execute_input":"2025-02-03T14:30:14.940790Z","iopub.status.idle":"2025-02-03T14:30:19.357517Z","shell.execute_reply.started":"2025-02-03T14:30:14.940769Z","shell.execute_reply":"2025-02-03T14:30:19.356695Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.14.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport torch\nimport emoji\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom imblearn.over_sampling import SMOTE\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:04.721121Z","iopub.execute_input":"2025-02-03T18:59:04.721433Z","iopub.status.idle":"2025-02-03T18:59:05.146337Z","shell.execute_reply.started":"2025-02-03T18:59:04.721410Z","shell.execute_reply":"2025-02-03T18:59:05.145435Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Define text cleaning function\ndef clean_text(text):\n    text = text.encode('latin-1', errors='ignore').decode('utf-8', errors='ignore')  \n    text = emoji.demojize(text)  \n    text = text.lower()  \n    text = re.sub(r\"@\\w+\", \"\", text)  \n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  \n    text = re.sub(r\"\\s+\", \" \", text).strip()  \n    return text\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/twitter-racism/twitter_racism_dataset.csv\")\n\n# Select relevant columns\ndf = df[[\"Text\", \"oh_label\"]]\n\n# Apply text cleaning\ndf[\"Text\"] = df[\"Text\"].apply(clean_text)\n\n# Convert labels if needed\ndf[\"oh_label\"] = df[\"oh_label\"].astype(int)  # Ensure labels are integers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:09.805948Z","iopub.execute_input":"2025-02-03T18:59:09.806670Z","iopub.status.idle":"2025-02-03T18:59:10.990183Z","shell.execute_reply.started":"2025-02-03T18:59:09.806625Z","shell.execute_reply":"2025-02-03T18:59:10.989433Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:16.565823Z","iopub.execute_input":"2025-02-03T18:59:16.566152Z","iopub.status.idle":"2025-02-03T18:59:16.574340Z","shell.execute_reply.started":"2025-02-03T18:59:16.566126Z","shell.execute_reply":"2025-02-03T18:59:16.573500Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                Text  oh_label\n0  muslim mob violence against hindus in banglade...         1\n1                                                            0\n2  islamophobia is like the idea of naziphobia. i...         1\n3  finally i'm all caught up, and that sudden dea...         0\n4                                             *hugs*         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>oh_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>muslim mob violence against hindus in banglade...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>islamophobia is like the idea of naziphobia. i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>finally i'm all caught up, and that sudden dea...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>*hugs*</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"print(df[\"oh_label\"].value_counts())\nimport matplotlib.pyplot as plt\n\ndf[\"oh_label\"].value_counts().plot(kind=\"bar\", color=[\"blue\", \"orange\"])\nplt.xlabel(\"Label\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Labels in Dataset\")\nplt.xticks(ticks=[0, 1], labels=[\"Negative (0)\", \"Positive (1)\"])\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:20.085976Z","iopub.execute_input":"2025-02-03T18:59:20.086276Z","iopub.status.idle":"2025-02-03T18:59:20.239140Z","shell.execute_reply.started":"2025-02-03T18:59:20.086255Z","shell.execute_reply":"2025-02-03T18:59:20.238360Z"}},"outputs":[{"name":"stdout","text":"oh_label\n0    11501\n1     1970\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Load tokenizer and model\nmodel_checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModel.from_pretrained(model_checkpoint)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:23.615984Z","iopub.execute_input":"2025-02-03T18:59:23.616275Z","iopub.status.idle":"2025-02-03T18:59:24.640011Z","shell.execute_reply.started":"2025-02-03T18:59:23.616253Z","shell.execute_reply":"2025-02-03T18:59:24.639091Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Function to get embeddings from RoBERTa\ndef get_roberta_embeddings(texts, batch_size=16):\n    model.eval()  # Set model to evaluation mode\n    embeddings = []\n\n    with torch.no_grad():  # No gradient calculation for faster inference\n        for i in range(0, len(texts), batch_size):\n            batch_texts = texts[i : i + batch_size]\n            \n            # Tokenize batch\n            encoded_inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n            \n            # Forward pass through RoBERTa\n            outputs = model(**encoded_inputs)\n            \n            # Extract the [CLS] token embeddings (pooled output)\n            cls_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n            embeddings.extend(cls_embeddings)\n\n    return np.array(embeddings)\n\n# Get embeddings for the dataset\nX = get_roberta_embeddings(df[\"Text\"].tolist())\n\n# Labels\ny = df[\"oh_label\"].values\n\nprint(\"Embeddings Shape:\", X.shape)  # Should be (num_samples, 768)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:59:32.497200Z","iopub.execute_input":"2025-02-03T18:59:32.497557Z","iopub.status.idle":"2025-02-03T19:05:55.544361Z","shell.execute_reply.started":"2025-02-03T18:59:32.497522Z","shell.execute_reply":"2025-02-03T19:05:55.543579Z"}},"outputs":[{"name":"stdout","text":"Embeddings Shape: (13471, 768)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"X = get_roberta_embeddings(df[\"Text\"].tolist())\ny = df[\"oh_label\"].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:06:29.384474Z","iopub.execute_input":"2025-02-03T19:06:29.384775Z","iopub.status.idle":"2025-02-03T19:12:27.968074Z","shell.execute_reply.started":"2025-02-03T19:06:29.384753Z","shell.execute_reply":"2025-02-03T19:12:27.967343Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:12:37.904240Z","iopub.execute_input":"2025-02-03T19:12:37.904547Z","iopub.status.idle":"2025-02-03T19:12:37.918668Z","shell.execute_reply.started":"2025-02-03T19:12:37.904522Z","shell.execute_reply":"2025-02-03T19:12:37.917987Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Apply SMOTE ONLY to training data\nsmote = SMOTE(random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:12:42.133667Z","iopub.execute_input":"2025-02-03T19:12:42.133964Z","iopub.status.idle":"2025-02-03T19:12:42.413777Z","shell.execute_reply.started":"2025-02-03T19:12:42.133941Z","shell.execute_reply":"2025-02-03T19:12:42.412844Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(\"Class distribution after SMOTE:\")\nprint(pd.Series(y_train_res).value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:12:45.123611Z","iopub.execute_input":"2025-02-03T19:12:45.123983Z","iopub.status.idle":"2025-02-03T19:12:45.130517Z","shell.execute_reply.started":"2025-02-03T19:12:45.123955Z","shell.execute_reply":"2025-02-03T19:12:45.129727Z"}},"outputs":[{"name":"stdout","text":"Class distribution after SMOTE:\n0    9206\n1    9206\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"log_reg = LogisticRegression(max_iter=1000)\nlog_reg.fit(X_train_res, y_train_res)\ny_pred = log_reg.predict(X_test)\n\n# Evaluate model performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:12:50.503919Z","iopub.execute_input":"2025-02-03T19:12:50.504201Z","iopub.status.idle":"2025-02-03T19:13:00.293844Z","shell.execute_reply.started":"2025-02-03T19:12:50.504181Z","shell.execute_reply":"2025-02-03T19:13:00.292973Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9009276437847866\nF1 Score: 0.9076734784980012\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94      2295\n           1       0.62      0.88      0.72       400\n\n    accuracy                           0.90      2695\n   macro avg       0.80      0.89      0.83      2695\nweighted avg       0.92      0.90      0.91      2695\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\nxgb_model = xgb.XGBClassifier(\n    objective=\"binary:logistic\",  # Changed from multi-class\n    eval_metric=\"logloss\",\n    use_label_encoder=False,\n    n_estimators=300,\n    max_depth=3,\n    learning_rate=0.1,\n    subsample=0.6,\n    colsample_bytree=1.0,\n    random_state=42\n)\nxgb_model.fit(X_train_res, y_train_res)\ny_pred = xgb_model.predict(X_test)\n\n# Evaluate model performance\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:13:13.772230Z","iopub.execute_input":"2025-02-03T19:13:13.772523Z","iopub.status.idle":"2025-02-03T19:13:27.493144Z","shell.execute_reply.started":"2025-02-03T19:13:13.772498Z","shell.execute_reply":"2025-02-03T19:13:27.492446Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9146567717996289\nF1 Score: 0.9186405162430925\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.97      0.93      0.95      2295\n           1       0.67      0.84      0.75       400\n\n    accuracy                           0.91      2695\n   macro avg       0.82      0.89      0.85      2695\nweighted avg       0.93      0.91      0.92      2695\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Modified Hyperparameter Tuning\nparam_grid = {\n    \"n_estimators\": [100, 200, 300],\n    \"max_depth\": [3, 6, 9],\n    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n    \"subsample\": [0.6, 0.8, 1.0],\n    \"colsample_bytree\": [0.6, 0.8, 1.0],\n    \"gamma\": [0, 0.1, 0.2, 0.3],\n    \"reg_lambda\": [0, 1, 10],\n    \"reg_alpha\": [0, 1, 10],\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:13:46.374260Z","iopub.execute_input":"2025-02-03T19:13:46.374556Z","iopub.status.idle":"2025-02-03T19:13:46.378878Z","shell.execute_reply.started":"2025-02-03T19:13:46.374532Z","shell.execute_reply":"2025-02-03T19:13:46.377940Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"Hyperparameter","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n\nrandom_search = RandomizedSearchCV(\n    xgb.XGBClassifier(\n        objective=\"binary:logistic\",  # Fixed objective\n        eval_metric=\"logloss\",\n        use_label_encoder=False,\n        random_state=42\n    ),\n    param_distributions=param_grid,\n    n_iter=20,\n    scoring=\"f1_weighted\",\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\nrandom_search.fit(X_train_res, y_train_res)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:13:53.124116Z","iopub.execute_input":"2025-02-03T19:13:53.124396Z","iopub.status.idle":"2025-02-03T19:33:00.858048Z","shell.execute_reply.started":"2025-02-03T19:13:53.124373Z","shell.execute_reply":"2025-02-03T19:33:00.857034Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 20 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"RandomizedSearchCV(cv=3,\n                   estimator=XGBClassifier(base_score=None, booster=None,\n                                           callbacks=None,\n                                           colsample_bylevel=None,\n                                           colsample_bynode=None,\n                                           colsample_bytree=None, device=None,\n                                           early_stopping_rounds=None,\n                                           enable_categorical=False,\n                                           eval_metric='logloss',\n                                           feature_types=None, gamma=None,\n                                           grow_policy=None,\n                                           importance_type=None,\n                                           interaction_constraints=None,\n                                           learning...\n                                           n_estimators=None, n_jobs=None,\n                                           num_parallel_tree=None,\n                                           random_state=42, ...),\n                   n_iter=20, n_jobs=-1,\n                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n                                        'gamma': [0, 0.1, 0.2, 0.3],\n                                        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n                                        'max_depth': [3, 6, 9],\n                                        'n_estimators': [100, 200, 300],\n                                        'reg_alpha': [0, 1, 10],\n                                        'reg_lambda': [0, 1, 10],\n                                        'subsample': [0.6, 0.8, 1.0]},\n                   scoring='f1_weighted', verbose=2)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=XGBClassifier(base_score=None, booster=None,\n                                           callbacks=None,\n                                           colsample_bylevel=None,\n                                           colsample_bynode=None,\n                                           colsample_bytree=None, device=None,\n                                           early_stopping_rounds=None,\n                                           enable_categorical=False,\n                                           eval_metric=&#x27;logloss&#x27;,\n                                           feature_types=None, gamma=None,\n                                           grow_policy=None,\n                                           importance_type=None,\n                                           interaction_constraints=None,\n                                           learning...\n                                           n_estimators=None, n_jobs=None,\n                                           num_parallel_tree=None,\n                                           random_state=42, ...),\n                   n_iter=20, n_jobs=-1,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3],\n                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n                                        &#x27;max_depth&#x27;: [3, 6, 9],\n                                        &#x27;n_estimators&#x27;: [100, 200, 300],\n                                        &#x27;reg_alpha&#x27;: [0, 1, 10],\n                                        &#x27;reg_lambda&#x27;: [0, 1, 10],\n                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n                   scoring=&#x27;f1_weighted&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=XGBClassifier(base_score=None, booster=None,\n                                           callbacks=None,\n                                           colsample_bylevel=None,\n                                           colsample_bynode=None,\n                                           colsample_bytree=None, device=None,\n                                           early_stopping_rounds=None,\n                                           enable_categorical=False,\n                                           eval_metric=&#x27;logloss&#x27;,\n                                           feature_types=None, gamma=None,\n                                           grow_policy=None,\n                                           importance_type=None,\n                                           interaction_constraints=None,\n                                           learning...\n                                           n_estimators=None, n_jobs=None,\n                                           num_parallel_tree=None,\n                                           random_state=42, ...),\n                   n_iter=20, n_jobs=-1,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3],\n                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n                                        &#x27;max_depth&#x27;: [3, 6, 9],\n                                        &#x27;n_estimators&#x27;: [100, 200, 300],\n                                        &#x27;reg_alpha&#x27;: [0, 1, 10],\n                                        &#x27;reg_lambda&#x27;: [0, 1, 10],\n                                        &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n                   scoring=&#x27;f1_weighted&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"import joblib\nfrom transformers import AutoTokenizer, AutoModel\n\n# Save the complete pipeline components\njoblib.dump({\n    'xgb_model': xgb_model,\n    'roberta_tokenizer': tokenizer,\n    'roberta_model': model,\n    'clean_text_func': clean_text\n}, 'racism_detection_pipeline.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:38:16.321173Z","iopub.execute_input":"2025-02-03T19:38:16.321512Z","iopub.status.idle":"2025-02-03T19:38:17.108050Z","shell.execute_reply.started":"2025-02-03T19:38:16.321485Z","shell.execute_reply":"2025-02-03T19:38:17.107313Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['racism_detection_pipeline.pkl']"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/racism_detection_pipeline\", 'zip', \"/kaggle/working\", \"racism_detection_pipeline.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:40:25.127755Z","iopub.execute_input":"2025-02-03T19:40:25.128090Z","iopub.status.idle":"2025-02-03T19:40:49.660883Z","shell.execute_reply.started":"2025-02-03T19:40:25.128062Z","shell.execute_reply":"2025-02-03T19:40:49.660132Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/racism_detection_pipeline.zip'"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"Second method","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset, DatasetDict\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n\n# Define your text cleaning function\ndef clean_text(text):\n    text = text.encode('latin-1', errors='ignore').decode('utf-8', errors='ignore')\n    text = emoji.demojize(text)  \n    text = text.lower()  \n    text = re.sub(r\"@\\w+\", \"\", text)  \n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  \n    text = re.sub(r\"\\s+\", \" \", text).strip()  \n    return text\n\n# Load dataset (Replace with your dataset file)\ndf = pd.read_csv(\"/kaggle/input/twitter-racism/twitter_racism_dataset.csv\")\ndf = df[[\"Text\", \"oh_label\"]]  # Select relevant columns\ndf = df.rename(columns={\"Text\": \"text\", \"oh_label\": \"label\"})  # Rename for consistency\n\n# Clean text\ndf[\"text\"] = df[\"text\"].apply(clean_text)\n\n# Convert labels if necessary (assuming 0: racism, 1: non-racism)\ndf[\"label\"] = df[\"label\"].astype(int)\n\n# Split into train/test\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Convert to Hugging Face dataset\ndataset = DatasetDict({\n    \"train\": Dataset.from_pandas(train_df),\n    \"test\": Dataset.from_pandas(test_df)\n})\n\n# Load the tokenizer and model\nmodel_checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\ntokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\n# Tokenize datasets\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# Remove original text column\ntokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\ntokenized_datasets.set_format(\"torch\")\n\n# Load the model with num_labels=2 for binary classification\n# Load the model with num_labels=2 for binary classification and ignore size mismatch\nmodel = RobertaForSequenceClassification.from_pretrained(\n    model_checkpoint, \n    num_labels=2,\n    ignore_mismatched_sizes=True  # Add this parameter\n)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    num_train_epochs=5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    report_to=\"none\"  # Disable WandB reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    compute_metrics=compute_metrics,  # Attach the metric function\n)\n# Disable WandB logging\nos.environ[\"WANDB_DISABLED\"] = \"true\"  # Disable WandB logging\n\n# Train the model\ntrainer.train()\n\ndef compute_metrics(eval_pred):\n    metric = load_metric(\"accuracy\")\n    logits, labels = eval_pred  # Unpack the tuple directly\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T16:59:20.568973Z","iopub.execute_input":"2025-02-03T16:59:20.569445Z","iopub.status.idle":"2025-02-03T17:11:58.281418Z","shell.execute_reply.started":"2025-02-03T16:59:20.569405Z","shell.execute_reply":"2025-02-03T17:11:58.280576Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10776 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51db84264c3644238d56a4e70b80a43a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2695 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5959b18e15495fadcec873b19e1de7"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3370' max='3370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3370/3370 12:25, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.228300</td>\n      <td>0.161946</td>\n      <td>0.936920</td>\n      <td>0.937490</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.119800</td>\n      <td>0.209166</td>\n      <td>0.933581</td>\n      <td>0.934779</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.098600</td>\n      <td>0.358027</td>\n      <td>0.927644</td>\n      <td>0.925401</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.055500</td>\n      <td>0.415408</td>\n      <td>0.925046</td>\n      <td>0.925941</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.045400</td>\n      <td>0.462896</td>\n      <td>0.924304</td>\n      <td>0.924988</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}